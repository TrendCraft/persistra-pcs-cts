/**
 * Pilot-Ready Acceptance Tests for OptimizedMemoryRetrieval Fixes
 * 
 * Tests the 2 critical edge case fixes:
 * 1. Dedupe with missing source_id and id (content hash fallback)
 * 2. Diversity enforcement respecting maxPerSource and finalCoreCount (swap strategy)
 * 
 * Plus 2 validation tests:
 * 3. Timestamp preference for metadata.timestamp
 * 4. Log truthfulness (no "graph traversal" language)
 */

const crypto = require('crypto');

// Mock OptimizedMemoryRetrieval class with fixed methods
class OptimizedMemoryRetrievalMock {
  getStableMemoryKey(memory) {
    // Best: use provenance source_id (canonical stable identifier)
    if (memory.metadata?.source_id) {
      return memory.metadata.source_id;
    }
    
    // Fallback: use memory.id if present
    if (memory.id) {
      return memory.id;
    }
    
    // Last resort: derive stable key from content + type + timestamp
    const contentSample = (memory.content || memory.formattedContent || '').substring(0, 100);
    const type = memory.type || memory.metadata?.chunk_type || 'unknown';
    const timestamp = memory.metadata?.timestamp || memory.timestamp || Date.now();
    const hashInput = `${contentSample}|${type}|${timestamp}`;
    
    return crypto.createHash('md5').update(hashInput).digest('hex').substring(0, 16);
  }
  
  applyDiversityQuotas(sortedMemories, targetCount, quotaConfig) {
    const { maxPerSource, minUniqueTypes, minUniqueSources } = quotaConfig;
    
    const selected = [];
    const sourceCount = new Map();
    const typeSet = new Set();
    const sourceSet = new Set();
    
    // First pass: Greedy selection with quotas
    for (const memory of sortedMemories) {
      if (selected.length >= targetCount) break;
      
      const sourceId = memory.metadata?.source_id || 'unknown';
      const sourceKind = memory.metadata?.source_kind || 'unknown';
      const chunkType = memory.metadata?.chunk_type || memory.chunk_type || memory.type || 'unknown';
      const typeKey = `${sourceKind}:${chunkType}`;
      
      const currentSourceCount = sourceCount.get(sourceId) || 0;
      if (currentSourceCount >= maxPerSource) {
        continue;
      }
      
      selected.push(memory);
      sourceCount.set(sourceId, currentSourceCount + 1);
      typeSet.add(typeKey);
      sourceSet.add(sourceId);
    }
    
    // Second pass: Fill remaining slots
    if (selected.length < targetCount) {
      const selectedKeys = new Set(selected.map(m => this.getStableMemoryKey(m)));
      
      for (const memory of sortedMemories) {
        if (selected.length >= targetCount) break;
        
        const memoryKey = this.getStableMemoryKey(memory);
        if (selectedKeys.has(memoryKey)) continue;
        
        selected.push(memory);
        selectedKeys.add(memoryKey);
      }
    }
    
    // ENFORCEMENT PASS: Swap to add new sources
    if (sourceSet.size < minUniqueSources && selected.length > 0) {
      const selectedKeys = new Set(selected.map(m => this.getStableMemoryKey(m)));
      
      const newSourceCandidates = [];
      for (const memory of sortedMemories) {
        if (sourceSet.size >= minUniqueSources) break;
        
        const memoryKey = this.getStableMemoryKey(memory);
        if (selectedKeys.has(memoryKey)) continue;
        
        const sourceId = memory.metadata?.source_id || 'unknown';
        if (sourceSet.has(sourceId)) continue;
        
        newSourceCandidates.push(memory);
      }
      
      for (const candidate of newSourceCandidates) {
        if (sourceSet.size >= minUniqueSources) break;
        
        const candidateSourceId = candidate.metadata?.source_id || 'unknown';
        
        const overrepresentedSources = Array.from(sourceCount.entries())
          .filter(([source, count]) => count > 1)
          .sort((a, b) => b[1] - a[1]);
        
        if (overrepresentedSources.length === 0) {
          if (selected.length < targetCount) {
            selected.push(candidate);
            selectedKeys.add(this.getStableMemoryKey(candidate));
            sourceSet.add(candidateSourceId);
            sourceCount.set(candidateSourceId, 1);
          }
          continue;
        }
        
        const [overrepSource, overrepCount] = overrepresentedSources[0];
        
        let lowestSalienceIndex = -1;
        let lowestSalience = Infinity;
        for (let i = 0; i < selected.length; i++) {
          const mem = selected[i];
          if ((mem.metadata?.source_id || 'unknown') === overrepSource) {
            if ((mem.salience || 0) < lowestSalience) {
              lowestSalience = mem.salience || 0;
              lowestSalienceIndex = i;
            }
          }
        }
        
        if (lowestSalienceIndex === -1) continue;
        
        const victim = selected[lowestSalienceIndex];
        selected[lowestSalienceIndex] = candidate;
        
        selectedKeys.delete(this.getStableMemoryKey(victim));
        selectedKeys.add(this.getStableMemoryKey(candidate));
        
        sourceCount.set(overrepSource, overrepCount - 1);
        sourceCount.set(candidateSourceId, 1);
        sourceSet.add(candidateSourceId);
      }
    }
    
    return { selected, sourceSet, sourceCount };
  }
}

// Test 1: Dedupe with missing source_id and id
function testDedupeWithMissingIds() {
  console.log('\n=== TEST 1: Dedupe with 20 memories missing ids + source_id ===');
  
  const retrieval = new OptimizedMemoryRetrievalMock();
  
  // Create 20 memories with NO source_id and NO id
  const memories = [];
  for (let i = 0; i < 20; i++) {
    memories.push({
      content: `Memory content ${i}`,
      type: 'test',
      metadata: {
        chunk_type: 'test_chunk',
        timestamp: Date.now() + i * 1000
      },
      salience: 0.8 - (i * 0.01)
    });
  }
  
  // Get stable keys for all memories
  const keys = memories.map(m => retrieval.getStableMemoryKey(m));
  const uniqueKeys = new Set(keys);
  
  console.log(`Created ${memories.length} memories with no source_id or id`);
  console.log(`Unique keys generated: ${uniqueKeys.size}`);
  console.log(`Sample keys: ${Array.from(uniqueKeys).slice(0, 3).join(', ')}`);
  
  // Verify all keys are unique (not all 'unknown')
  const allUnique = uniqueKeys.size === memories.length;
  console.log(`‚úì All keys unique: ${allUnique ? 'PASS' : 'FAIL'}`);
  
  // Verify keys are stable (same memory = same key)
  const key1 = retrieval.getStableMemoryKey(memories[0]);
  const key2 = retrieval.getStableMemoryKey(memories[0]);
  console.log(`‚úì Keys stable: ${key1 === key2 ? 'PASS' : 'FAIL'}`);
  
  return allUnique && (key1 === key2);
}

// Test 2: Quota enforcement with monopoly source
function testQuotaEnforcement() {
  console.log('\n=== TEST 2: Quota enforcement with 12 from 1 source requiring 5 sources ===');
  
  const retrieval = new OptimizedMemoryRetrievalMock();
  
  // Create 12 high-salience memories from source A
  const memories = [];
  for (let i = 0; i < 12; i++) {
    memories.push({
      content: `Source A memory ${i}`,
      type: 'test',
      metadata: {
        source_id: 'source_a',
        source_kind: 'test',
        chunk_type: 'test_chunk'
      },
      salience: 0.9 - (i * 0.01)
    });
  }
  
  // Add 5 lower-salience memories from sources B, C, D, E, F
  ['source_b', 'source_c', 'source_d', 'source_e', 'source_f'].forEach((sourceId, idx) => {
    memories.push({
      content: `${sourceId} memory`,
      type: 'test',
      metadata: {
        source_id: sourceId,
        source_kind: 'test',
        chunk_type: 'test_chunk'
      },
      salience: 0.5 - (idx * 0.01)
    });
  });
  
  // Sort by salience (highest first)
  memories.sort((a, b) => b.salience - a.salience);
  
  const quotaConfig = {
    maxPerSource: 2,
    minUniqueTypes: 1,
    minUniqueSources: 5
  };
  
  const { selected, sourceSet, sourceCount } = retrieval.applyDiversityQuotas(memories, 12, quotaConfig);
  
  console.log(`Selected ${selected.length} memories`);
  console.log(`Unique sources: ${sourceSet.size}`);
  console.log(`Source distribution: ${JSON.stringify(Array.from(sourceCount.entries()))}`);
  
  // Verify constraints
  const respectsTargetCount = selected.length <= 12;
  const meetsMinSources = sourceSet.size >= 5;
  const respectsMaxPerSource = Array.from(sourceCount.values()).every(count => count <= 2);
  
  console.log(`‚úì Respects targetCount (‚â§12): ${respectsTargetCount ? 'PASS' : 'FAIL'}`);
  console.log(`‚úì Meets minUniqueSources (‚â•5): ${meetsMinSources ? 'PASS' : 'FAIL'}`);
  console.log(`‚úì Respects maxPerSource (‚â§2): ${respectsMaxPerSource ? 'PASS' : 'FAIL'}`);
  
  return respectsTargetCount && meetsMinSources && respectsMaxPerSource;
}

// Test 3: Timestamp preference
function testTimestampPreference() {
  console.log('\n=== TEST 3: Timestamp preference for metadata.timestamp ===');
  
  const memories = [
    {
      content: 'Memory 1',
      timestamp: 1000000000000, // Old timestamp (2001)
      metadata: {
        timestamp: Date.now() // Recent metadata.timestamp
      }
    },
    {
      content: 'Memory 2',
      timestamp: Date.now(), // Recent timestamp
      metadata: {} // No metadata.timestamp
    },
    {
      content: 'Memory 3',
      metadata: {
        timestamp: Date.now() - 86400000 // Yesterday
      }
    }
  ];
  
  // Simulate provenance-first timestamp extraction
  const timestamps = memories
    .map(m => m.metadata?.timestamp ?? m.timestamp)
    .filter(t => t && typeof t === 'number');
  
  console.log(`Extracted ${timestamps.length} timestamps`);
  console.log(`Memory 1 timestamp: ${timestamps[0]} (should be recent, not 2001)`);
  console.log(`Memory 2 timestamp: ${timestamps[1]} (should be recent from fallback)`);
  console.log(`Memory 3 timestamp: ${timestamps[2]} (should be yesterday)`);
  
  // Verify Memory 1 uses metadata.timestamp (recent) not timestamp (2001)
  const usesMetadataFirst = timestamps[0] > 1600000000000; // After 2020
  console.log(`‚úì Uses metadata.timestamp first: ${usesMetadataFirst ? 'PASS' : 'FAIL'}`);
  
  return usesMetadataFirst;
}

// Test 4: Log truthfulness
function testLogTruthfulness() {
  console.log('\n=== TEST 4: Verify no remaining "graph traversal" language ===');
  
  const fs = require('fs');
  const path = require('path');
  
  const retrievalFile = path.join(__dirname, 'OptimizedMemoryRetrieval.js');
  const content = fs.readFileSync(retrievalFile, 'utf8');
  
  // Check for problematic phrases
  const problematicPhrases = [
    'graph expansion',
    'graph traversal',
    'edge-following',
    'following edges',
    'Neo4j edges'
  ];
  
  const found = [];
  problematicPhrases.forEach(phrase => {
    const regex = new RegExp(phrase, 'gi');
    const matches = content.match(regex);
    if (matches && matches.length > 0) {
      // Check if it's in a comment explaining what we DON'T do
      const lines = content.split('\n');
      let inExplanation = false;
      lines.forEach(line => {
        if (regex.test(line)) {
          if (line.includes('NOT') || line.includes('not') || line.includes('semantic')) {
            inExplanation = true;
          } else {
            found.push({ phrase, line: line.trim() });
          }
        }
      });
    }
  });
  
  console.log(`Checked for ${problematicPhrases.length} problematic phrases`);
  if (found.length > 0) {
    console.log(`‚ö†Ô∏è  Found ${found.length} instances:`);
    found.forEach(({ phrase, line }) => {
      console.log(`   - "${phrase}" in: ${line.substring(0, 80)}...`);
    });
  } else {
    console.log(`‚úì No misleading "graph traversal" language found: PASS`);
  }
  
  // Check for correct "semantic expansion" language
  const hasSemanticExpansion = content.includes('semantic expansion') || content.includes('Semantic expansion');
  console.log(`‚úì Uses "semantic expansion" terminology: ${hasSemanticExpansion ? 'PASS' : 'FAIL'}`);
  
  return found.length === 0 && hasSemanticExpansion;
}

// Run all tests
function runAllTests() {
  console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
  console.log('‚ïë  PILOT-READY ACCEPTANCE TESTS: OptimizedMemoryRetrieval Fixes ‚ïë');
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
  
  const results = {
    test1: testDedupeWithMissingIds(),
    test2: testQuotaEnforcement(),
    test3: testTimestampPreference(),
    test4: testLogTruthfulness()
  };
  
  console.log('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
  console.log('‚ïë  TEST RESULTS SUMMARY                                          ‚ïë');
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
  console.log(`Test 1 (Dedupe with missing IDs):     ${results.test1 ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`Test 2 (Quota enforcement):           ${results.test2 ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`Test 3 (Timestamp preference):        ${results.test3 ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`Test 4 (Log truthfulness):            ${results.test4 ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  
  const allPassed = Object.values(results).every(r => r);
  console.log('\n' + (allPassed ? 'üéâ ALL TESTS PASSED - PILOT READY' : '‚ö†Ô∏è  SOME TESTS FAILED - NEEDS FIXES'));
  
  return allPassed;
}

// Run tests if executed directly
if (require.main === module) {
  const success = runAllTests();
  process.exit(success ? 0 : 1);
}

module.exports = { runAllTests };
